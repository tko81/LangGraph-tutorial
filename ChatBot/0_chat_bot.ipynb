{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4451a6c9c85de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿™æ˜¯ä¸€ä¸ªstate schema\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    # add_messageæ˜¯ä¸€ä¸ªreducer, æœªæŒ‡å®šreduceré»˜è®¤é‡‡ç”¨è¦†ç›–çš„ç­–ç•¥\n",
    "    # https://langchain-ai.github.io/langgraph/concepts/low_level/#default-reducer\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf27176b0abdb7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# åŠ è½½ .env æ–‡ä»¶\n",
    "load_dotenv()\n",
    "\n",
    "llm = init_chat_model(\"openai:gpt-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c69ddfde75c50f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7b01e2115370>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è¿™æ˜¯ä¸€ä¸ªnodeï¼Œæ¥å—ä¸€ä¸ªstateä½œä¸ºå‚æ•°ï¼Œå°†èŠå¤©æ¨¡å‹åˆå¹¶åˆ°ä¸€ä¸ªç®€å•çš„èŠ‚ç‚¹ä¸­\n",
    "# State ä¸­çš„ add_messages å‡½æ•°å°†æŠŠ LLM çš„å“åº”æ¶ˆæ¯é™„åŠ åˆ°çŠ¶æ€ä¸­å·²æœ‰çš„æ¶ˆæ¯listä¸­\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f4cc39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7b01e2115370>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ·»åŠ ä¸€ä¸ª entry ç‚¹æ¥å‘Šè¯‰å›¾è¡¨æ¯æ¬¡è¿è¡Œæ—¶ä»å“ªé‡Œå¼€å§‹å·¥ä½œ\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "# æ·»åŠ  exit ç‚¹ï¼ŒæŒ‡ç¤ºå›¾è¡¨åº”åœ¨ä½•å¤„ç»“æŸæ‰§è¡Œ\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "358ca3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¼–è¯‘graphï¼Œåœ¨è¿è¡Œå›¾è¡¨ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦ç¼–è¯‘å®ƒã€‚è¿™å°†åˆ›å»ºä¸€ä¸ª CompiledGraph ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨stateè°ƒç”¨å®ƒ\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d727f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å›¾è¡¨\n",
    "# ä»¥ä½¿ç”¨ get_graph æ–¹æ³•å’Œå…¶ä¸­ä¸€ç§â€œdrawâ€æ–¹æ³•ï¼Œä¾‹å¦‚ draw_ascii æˆ– draw_png æ¥å¯è§†åŒ–å›¾å½¢ã€‚æ¯ç§ draw æ–¹æ³•éƒ½éœ€è¦é¢å¤–çš„ä¾èµ–é¡¹\n",
    "# from IPython.display import Image, display\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c254de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡ŒèŠå¤©æœºå™¨äºº\n",
    "# def stream_graph_updates(user_input: str):\n",
    "#     for event in graph.stream(\n",
    "#             {\n",
    "#                 \"messages\": [\n",
    "#                     {\"role\": \"user\", \"content\": user_input}\n",
    "#                 ]\n",
    "#             }\n",
    "#         ):\n",
    "#         for value in event.values():\n",
    "#             print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "# while True:\n",
    "#     try:\n",
    "#         user_input = input(\"User: \")\n",
    "#         if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "#             print(\"Goodbye!\")\n",
    "#             break\n",
    "#         stream_graph_updates(user_input)\n",
    "#     except:\n",
    "#         # fallback if input() is not available\n",
    "#         user_input = \"What do you know about LangGraph?\"\n",
    "#         print(\"User: \" + user_input)\n",
    "#         stream_graph_updates(user_input)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb7d6874bbbbc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T05:04:28.229807Z",
     "start_time": "2025-08-15T02:17:13.251419Z"
    }
   },
   "outputs": [],
   "source": [
    "# è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ›´è¯¦ç»†çš„ç‰ˆæœ¬æ¥æ¼”ç¤ºstreamçš„å·¥ä½œè¿‡ç¨‹\n",
    "def detailed_stream_demo(user_input: str):\n",
    "    print(f\"ğŸ”¹ ç”¨æˆ·è¾“å…¥: {user_input}\")\n",
    "    print(\"ğŸ”¹ å¼€å§‹æµå¼æ‰§è¡Œå›¾...\")\n",
    "\n",
    "    # æ„é€ è¾“å…¥æ•°æ®\n",
    "    input_data = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "    }\n",
    "    print(f\"ğŸ”¹ è¾“å…¥æ•°æ®ç»“æ„: {input_data}\")\n",
    "\n",
    "    # å¼€å§‹æµå¼æ‰§è¡Œ\n",
    "    # eventæ˜¯ä¸€ä¸ªå­—å…¸ï¼Œkeyä¸ºèŠ‚ç‚¹çš„nameï¼Œvalueæ˜¯ä¸€ä¸ªmessage list\n",
    "    for i, event in enumerate(graph.stream(input_data), 1):\n",
    "        print(f\"\\nğŸ“¦ äº‹ä»¶ {i}:\")\n",
    "        print(f\"   äº‹ä»¶ç±»å‹: {type(event)}\")\n",
    "        print(f\"   äº‹ä»¶é”®: {list(event.keys())}\")\n",
    "\n",
    "        # éå†äº‹ä»¶ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹è¾“å‡º\n",
    "        for node_name, node_output in event.items():\n",
    "            print(f\"   ğŸ“ èŠ‚ç‚¹ '{node_name}' çš„è¾“å‡º:\")\n",
    "            print(f\"      æ¶ˆæ¯æ€»æ•°: {len(node_output['messages'])}\")\n",
    "\n",
    "            # éå†message list ä¸­çš„æ‰€æœ‰messageå¯¹è±¡ï¼ˆä¸æ˜¯å­—å…¸ï¼‰ï¼Œå› æ­¤åªèƒ½ä½¿ç”¨.xxæ¥è·å¾—xxå±æ€§\n",
    "            for j, msg in enumerate(node_output['messages']):\n",
    "                print(f\"      æ¶ˆæ¯ {j + 1}: {msg.type} -> {msg.content[:50]}...\")\n",
    "\n",
    "            # è·å–æœ€æ–°çš„AIå›å¤\n",
    "            if node_output['messages']:\n",
    "                latest_msg = node_output['messages'][-1]\n",
    "                if latest_msg.type == 'ai':\n",
    "                    print(f\"   ğŸ¤– AIå›å¤: {latest_msg.content}\")\n",
    "\n",
    "\n",
    "# æµ‹è¯•ä¸€ä¸‹è¿™ä¸ªè¯¦ç»†ç‰ˆæœ¬\n",
    "print(\"=\" * 60)\n",
    "print(\"è¯¦ç»†æµå¼æ‰§è¡Œæ¼”ç¤º\")\n",
    "print(\"=\" * 60)\n",
    "# detailed_stream_demo(\"ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d6cdd561440cca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n============================================================\\nè¯¦ç»†æµå¼æ‰§è¡Œæ¼”ç¤º\\n============================================================\\nğŸ”¹ ç”¨æˆ·è¾“å…¥: ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±\\nğŸ”¹ å¼€å§‹æµå¼æ‰§è¡Œå›¾...\\nğŸ”¹ è¾“å…¥æ•°æ®ç»“æ„: {'messages': [{'role': 'user', 'content': 'ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±'}]}\\n\\nğŸ“¦ äº‹ä»¶ 1:\\n   äº‹ä»¶ç±»å‹: <class 'dict'>\\n   äº‹ä»¶é”®: ['chatbot']\\n   ğŸ“ èŠ‚ç‚¹ 'chatbot' çš„è¾“å‡º:\\n      æ¶ˆæ¯æ€»æ•°: 1\\n      æ¶ˆæ¯ 1: ai -> ä½ å¥½ï¼æˆ‘æ˜¯ ChatGPTï¼Œä¸€æ¬¾ç”± OpenAI å¼€å‘çš„äººå·¥æ™ºèƒ½è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº GPT-4 æ¶æ„ã€‚æˆ‘...\\n   ğŸ¤– AIå›å¤: ä½ å¥½ï¼æˆ‘æ˜¯ ChatGPTï¼Œä¸€æ¬¾ç”± OpenAI å¼€å‘çš„äººå·¥æ™ºèƒ½è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº GPT-4 æ¶æ„ã€‚æˆ‘çš„ä¸»è¦åŠŸèƒ½æ˜¯é€šè¿‡è‡ªç„¶è¯­è¨€ä¸ç”¨æˆ·è¿›è¡Œäº¤æµï¼Œå¹¶æ ¹æ®æä¾›çš„ä¿¡æ¯æˆ–é—®é¢˜ï¼Œç»™å‡ºå°½é‡å‡†ç¡®å’Œæœ‰å¸®åŠ©çš„å›ç­”ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ å¤„ç†å„ç§ä»»åŠ¡ï¼Œæ¯”å¦‚æŸ¥æ‰¾ä¿¡æ¯ã€æ’°å†™æ–‡æœ¬ã€ç¿»è¯‘è¯­è¨€ã€è§£ç­”ç–‘éš¾ã€æä¾›å­¦ä¹ å»ºè®®ã€ç”šè‡³é—²èŠå¨±ä¹ã€‚\\n\\næ— è®ºä½ æœ‰ä»€ä¹ˆé—®é¢˜æˆ–éœ€æ±‚ï¼Œéƒ½å¯ä»¥éšæ—¶é—®æˆ‘å“¦ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ~\\n\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "============================================================\n",
    "è¯¦ç»†æµå¼æ‰§è¡Œæ¼”ç¤º\n",
    "============================================================\n",
    "ğŸ”¹ ç”¨æˆ·è¾“å…¥: ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±\n",
    "ğŸ”¹ å¼€å§‹æµå¼æ‰§è¡Œå›¾...\n",
    "ğŸ”¹ è¾“å…¥æ•°æ®ç»“æ„: {'messages': [{'role': 'user', 'content': 'ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±'}]}\n",
    "\n",
    "ğŸ“¦ äº‹ä»¶ 1:\n",
    "   äº‹ä»¶ç±»å‹: <class 'dict'>\n",
    "   äº‹ä»¶é”®: ['chatbot']\n",
    "   ğŸ“ èŠ‚ç‚¹ 'chatbot' çš„è¾“å‡º:\n",
    "      æ¶ˆæ¯æ€»æ•°: 1\n",
    "      æ¶ˆæ¯ 1: ai -> ä½ å¥½ï¼æˆ‘æ˜¯ ChatGPTï¼Œä¸€æ¬¾ç”± OpenAI å¼€å‘çš„äººå·¥æ™ºèƒ½è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº GPT-4 æ¶æ„ã€‚æˆ‘...\n",
    "   ğŸ¤– AIå›å¤: ä½ å¥½ï¼æˆ‘æ˜¯ ChatGPTï¼Œä¸€æ¬¾ç”± OpenAI å¼€å‘çš„äººå·¥æ™ºèƒ½è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº GPT-4 æ¶æ„ã€‚æˆ‘çš„ä¸»è¦åŠŸèƒ½æ˜¯é€šè¿‡è‡ªç„¶è¯­è¨€ä¸ç”¨æˆ·è¿›è¡Œäº¤æµï¼Œå¹¶æ ¹æ®æä¾›çš„ä¿¡æ¯æˆ–é—®é¢˜ï¼Œç»™å‡ºå°½é‡å‡†ç¡®å’Œæœ‰å¸®åŠ©çš„å›ç­”ã€‚æˆ‘å¯ä»¥å¸®åŠ©ä½ å¤„ç†å„ç§ä»»åŠ¡ï¼Œæ¯”å¦‚æŸ¥æ‰¾ä¿¡æ¯ã€æ’°å†™æ–‡æœ¬ã€ç¿»è¯‘è¯­è¨€ã€è§£ç­”ç–‘éš¾ã€æä¾›å­¦ä¹ å»ºè®®ã€ç”šè‡³é—²èŠå¨±ä¹ã€‚\n",
    "\n",
    "æ— è®ºä½ æœ‰ä»€ä¹ˆé—®é¢˜æˆ–éœ€æ±‚ï¼Œéƒ½å¯ä»¥éšæ—¶é—®æˆ‘å“¦ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ~\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b23c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"What's a 'node' in LangGraph?\",\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'url': 'https://langchain-ai.github.io/langgraph/concepts/low_level/',\n",
       "   'title': 'state graph node - GitHub Pages',\n",
       "   'content': 'To build your graph, you first define the state, you then add nodes and edges, and then you compile it. The schema of the `State` will be the input schema to all `Nodes` and `Edges` in the graph, and can be either a `TypedDict` or a `Pydantic` model. The reducer function is vital to telling the graph how to update the list of `Message` objects in the state with each state update (for example, when a node sends an update). graph.add_conditional_edges(\"node_a\", routing_function) Use `Command` when you need to **both** update the graph state **and** route to a different node. When you send updates from a subgraph node to a parent graph node for a key that\\'s shared by both parent and subgraph state schemas, you **must** define a reducer for the key you\\'re updating in the parent graph state.',\n",
       "   'score': 0.98599,\n",
       "   'raw_content': None},\n",
       "  {'url': 'https://medium.com/@cplog/introduction-to-langgraph-a-beginners-guide-14f9be027141',\n",
       "   'title': \"Introduction to LangGraph: A Beginner's Guide\",\n",
       "   'content': '*   **Stateful Graph:** LangGraph revolves around the concept of a stateful graph, where each node in the graph represents a step in your computation, and the graph maintains a state that is passed around and updated as the computation progresses. LangGraph supports conditional edges, allowing you to dynamically determine the next node to execute based on the current state of the graph. Image 11: Introduction to AI Agent with LangChain and LangGraph: A Beginnerâ€™s Guide Image 19: The Complete Guide to Building Your First AI Agent with LangGraph. Image 29: Understanding LangGraphâ€™s StateGraph: A Simple Guide Understanding LangGraphâ€™s StateGraph: A Simple Guide ---------------------------------------------------- ### LangGraph is a powerful framework that allows developers to define workflows as directed graphs.',\n",
       "   'score': 0.9834,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.36,\n",
       " 'request_id': '319afca2-0e21-460f-895f-a0c6df32baf6'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangGraph-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
